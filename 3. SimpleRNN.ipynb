{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "776f204dc1e0c14649d1537050d1f813e872b579605937dc2796ff8f0e52299a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Simple RNN实现IMDB情感分类\n",
    "讲解：https://www.bilibili.com/video/BV17A411e7qL?p=3  \n",
    "Slides：https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_2.pdf  \n",
    "代码1：https://setscholars.net/how-to-setup-a-simple-rnn-model-for-imdb-sentiment-analysis-in-keras/  \n",
    "代码2：https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/gzh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/gzh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "196/196 [==============================] - 38s 187ms/step - loss: 0.6671 - accuracy: 0.5648 - val_loss: 0.4522 - val_accuracy: 0.8048\n",
      "Epoch 2/5\n",
      "196/196 [==============================] - 35s 178ms/step - loss: 0.3878 - accuracy: 0.8320 - val_loss: 0.3789 - val_accuracy: 0.8394\n",
      "Epoch 3/5\n",
      "196/196 [==============================] - 37s 191ms/step - loss: 0.2566 - accuracy: 0.9023 - val_loss: 0.4134 - val_accuracy: 0.8182\n",
      "Epoch 4/5\n",
      "196/196 [==============================] - 39s 197ms/step - loss: 0.2050 - accuracy: 0.9217 - val_loss: 0.4255 - val_accuracy: 0.8404\n",
      "Epoch 5/5\n",
      "196/196 [==============================] - 39s 200ms/step - loss: 0.1126 - accuracy: 0.9626 - val_loss: 0.4344 - val_accuracy: 0.8483\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.4344 - accuracy: 0.8483\n",
      "Loss:0.43, Accuracy:0.85\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# load data and Set the number of words we want\n",
    "vocabulary=10000\n",
    "embedding_dim=32\n",
    "word_num=500\n",
    "state_dim=32\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary)\n",
    "'''\n",
    "print(); print(X_train.shape); print(X_train)\n",
    "print(); print(y_train.shape); print(y_train)\n",
    "print(); print(X_test.shape);  print(X_test)\n",
    "print(); print(y_test.shape);  print(y_test)\n",
    "'''\n",
    "# Convert movie review data to feature matrix\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=word_num)\n",
    "#print(); print(X_train.shape); print(X_train)\n",
    "\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=word_num)\n",
    "#print(); print(X_test.shape);  print(X_test)\n",
    "\n",
    "# setup a Simple RNN network\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary,embedding_dim,input_length=word_num))\n",
    "model.add(SimpleRNN(state_dim,return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=128, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "loss,score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Loss:%.2f, Accuracy:%.2f'%(loss,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}